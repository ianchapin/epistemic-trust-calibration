# Metrics and KPIs

This use case explores how epistemic trust calibration *might* apply to metrics, dashboards, and key performance indicators (KPIs).

This is a speculative example. It does not claim to improve performance, optimize outcomes, or select better metrics.

---

## Why This Is Interesting

Metrics and KPIs are widely used to:
- summarize complex systems
- track progress over time
- compare performance
- support decision-making

Because they are numerical and precise-looking, they often carry more authority than they deserve.

The risk is not that metrics are useless, but that they are treated as reality rather than representations of it.

---

## Common Failure Mode

A common failure mode is **proxy substitution**.

A metric is introduced as a stand-in for a complex goal.
Over time, attention shifts from the goal to the metric itself.

Examples include:
- optimizing for a KPI rather than the underlying outcome
- treating dashboard trends as ground truth
- assuming improvement in a metric implies improvement in the system

When this happens, the metric stops pointing at the goal and becomes the goal.

---

## Relevant Ambiguity Types

This scenario commonly involves:

- **Mapping Ambiguity**  
  Metrics are proxies. The relationship between the metric and the underlying phenomenon is indirect and often unstable.

- **Structural Ambiguity**  
  Metrics necessarily simplify and omit important variables, interactions, and edge cases.

- **Contextual Ambiguity**  
  Metrics designed for monitoring are used for incentives or control without reconsidering their limits.

- **Normative Ambiguity**  
  Value judgments about what matters are embedded in metric selection but often left implicit.

---

## How the Framework Might Apply

Rather than rejecting metrics, the framework suggests **annotating them**.

An annotation might include:
- what the metric was designed to represent
- what it explicitly does not capture
- the context in which it is reliable
- known ways the metric can be gamed or misread
- appropriate confidence when using it for decisions

The metric itself remains unchanged.
Only its interpretation and use are constrained.

---

## What This Does Not Do

This approach does not:
- validate the metric
- ensure alignment with goals
- prevent gaming
- resolve value conflicts
- decide which metrics should exist

It only makes trust assumptions explicit.

---

## Limits of This Application

Metrics are often tied to incentives, power, and accountability.

In such cases, explicit annotation may be ignored or overridden.
When metrics are treated as authoritative regardless of their limits, calibration has little effect.

If annotations become performative or ceremonial,
the framework has failed.

---

## Why This Is Speculative

This use case assumes:
- decision-makers are willing to treat metrics as tools rather than truths
- confidence can be downgraded without political cost
- judgment is allowed to override dashboards when necessary

These assumptions are not always valid.

This example exists to surface those tensions, not to resolve them.
